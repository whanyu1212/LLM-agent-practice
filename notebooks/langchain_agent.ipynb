{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace the standard sqlite3 module with pysqlite3\n",
    "# for compatibility with Chroma\n",
    "__import__('pysqlite3')\n",
    "import sys\n",
    "sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')\n",
    "\n",
    "import json\n",
    "import langchain\n",
    "import os\n",
    "import bs4\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_google_vertexai import VertexAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "from langgraph.prebuilt import chat_agent_executor\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import PipelinePromptTemplate, PromptTemplate\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.tools import StructuredTool\n",
    "from typing import Optional, Type\n",
    "from langchain.tools import BaseTool\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langgraph.checkpoint import MemorySaver  # an in-memory checkpointer\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "\n",
    "# credential json not required if you are working within vertex AI workbench\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/workspaces/LLM-agent-with-Gemini/fleet-anagram-244304-7dafcc771b2f.json\"\n",
    "\n",
    "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\") # only if you are using text embedding model from google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = ChatVertexAI(model=\"gemini-1.5-flash\")\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of Chain / Runnable Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "full_template = \"\"\"{introduction}\n",
    "\n",
    "{example}\n",
    "\n",
    "{start}\"\"\"\n",
    "\n",
    "\n",
    "full_prompt = PromptTemplate.from_template(full_template)\n",
    "\n",
    "introduction_template = \"\"\"You are a helpful assistant that can help me to complete the following API payload:\"\"\"\n",
    "introduction_prompt = PromptTemplate.from_template(introduction_template)\n",
    "\n",
    "example_template = \"\"\"Here are some examples of interactions you might have with me:\n",
    "\n",
    "Q: B16C, 1126911, FPP\n",
    "A: name:p.dsid,value, value:B16C, name:p.lot, value:1126911, name:p.pid, value:FPP\n",
    "\n",
    "Q: Y42M, 11952591, FQQP\n",
    "A: name:p.dsid, value:Y42M, name:p.lot, value:11952591, name:p.pid, value:FQQP\n",
    "\n",
    "Q: Y42M, 1252391, FPC\n",
    "A: name:p.dsid, value:Y42M, name:p.lot, value:1252391, name:p.pid, value:FPC\n",
    "\n",
    "Wrap the answer in a dictionary with the structure of the example above. The input will be a string with the format \"dsid, lot, pid\" \n",
    "and the output should be a dictionary with the keys \"name:p.dsid\", \"name:p.lot\", and \"name:p.pid\" with the corresponding values from the input string.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "example_prompt = PromptTemplate.from_template(example_template)\n",
    "\n",
    "start_template = \"\"\"Now, do this for real!\n",
    "\n",
    "Q: {input}\n",
    "A:\"\"\"\n",
    "start_prompt = PromptTemplate.from_template(start_template)\n",
    "\n",
    "input_prompts = [\n",
    "    (\"introduction\", introduction_prompt),\n",
    "    (\"example\", example_prompt),\n",
    "    (\"start\", start_prompt),\n",
    "]\n",
    "pipeline_prompt = PipelinePromptTemplate(\n",
    "    final_prompt=full_prompt, pipeline_prompts=input_prompts\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful assistant that can help me to complete the following API payload:\n",
      "\n",
      "Here are some examples of interactions you might have with me:\n",
      "\n",
      "Q: B16C, 1126911, FPP\n",
      "A: name:p.dsid,value, value:B16C, name:p.lot, value:1126911, name:p.pid, value:FPP\n",
      "\n",
      "Q: Y42M, 11952591, FQQP\n",
      "A: name:p.dsid, value:Y42M, name:p.lot, value:11952591, name:p.pid, value:FQQP\n",
      "\n",
      "Q: Y42M, 1252391, FPC\n",
      "A: name:p.dsid, value:Y42M, name:p.lot, value:1252391, name:p.pid, value:FPC\n",
      "\n",
      "Wrap the answer in a dictionary with the structure of the example above. The input will be a string with the format \"dsid, lot, pid\" \n",
      "and the output should be a dictionary with the keys \"name:p.dsid\", \"name:p.lot\", and \"name:p.pid\" with the corresponding values from the input string.\n",
      "\n",
      "\n",
      "\n",
      "Now, do this for real!\n",
      "\n",
      "Q: B16C, 1126911, FPP\n",
      "A:\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    pipeline_prompt.format(\n",
    "        input=\"B16C, 1126911, FPP\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Based on the format you provided, here is the output:\n",
      "\n",
      "```python\n",
      "{\n",
      "    \"name:p.dsid\": \"B47R\",\n",
      "    \"name:p.lot\": \"1952591\",\n",
      "    \"name:p.pid\": \"FPC\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "chain = pipeline_prompt | llm | StrOutputParser()\n",
    "\n",
    "output = chain.invoke({\"input\": \"B47R,1952591,FPC\"})\n",
    "\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It looks like the input \"testing\" does not follow the expected format \"dsid, lot, pid\". Please provide the input in the correct format.\n",
      "\n",
      "Here's an example of how the input should look: \"A12B, 123456, XYZ\"\n",
      "\n",
      "If you provide an input in this format, I can generate the corresponding dictionary for you.\n",
      "\n",
      "Let's try again! Please provide a valid input.\n"
     ]
    }
   ],
   "source": [
    "output = chain.invoke({\"input\": \"testing\"})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It appears you want to create an API payload based on the input string format. However, the question \"What is langchain?\" doesn't match the task provided. \n",
      "\n",
      "If you meant to ask about \"langchain\" instead of constructing an API payload, I'll answer that first:\n",
      "\n",
      "**LangChain** is a framework that enables the development of applications powered by language models. It allows developers to build applications that can understand and generate human language, facilitating the creation of chatbots, virtual assistants, and other language-based applications. LangChain provides tools and abstractions to streamline the integration of language models into software, making it easier to leverage their capabilities for various use cases.\n",
      "\n",
      "If you need assistance with the API payload, please provide the correct input string, and I can help you construct the appropriate dictionary.\n",
      "\n",
      "For example, if you provide the input string \"A12B, 345678, XYZ\", I can generate the corresponding dictionary as follows:\n",
      "\n",
      "```python\n",
      "input_string = \"A12B, 345678, XYZ\"\n",
      "dsid, lot, pid = input_string.split(\", \")\n",
      "payload = {\n",
      "    \"name:p.dsid\": dsid,\n",
      "    \"name:p.lot\": lot,\n",
      "    \"name:p.pid\": pid\n",
      "}\n",
      "print(payload)\n",
      "```\n",
      "\n",
      "This will output:\n",
      "\n",
      "```python\n",
      "{\n",
      "    \"name:p.dsid\": \"A12B\",\n",
      "    \"name:p.lot\": \"345678\",\n",
      "    \"name:p.pid\": \"XYZ\"\n",
      "}\n",
      "```\n",
      "\n",
      "Please provide the correct input string if you want me to generate a specific payload.\n"
     ]
    }
   ],
   "source": [
    "output = chain.invoke({\"input\": \"What is langchain\"})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval Augmented Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using LLM as a knowledge base retriever\n",
    "\n",
    "web_paths = [\n",
    "    \"https://google.github.io/styleguide/pyguide.html\",\n",
    "    \"https://google.github.io/styleguide/Rguide.html\",\n",
    "]\n",
    "\n",
    "docs = []\n",
    "for path in web_paths:\n",
    "    loader = WebBaseLoader(web_paths=(path,))\n",
    "    docs += loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "vectorstore = FAISS.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contextualize or internalize the current input question with the chat history\n",
    "# This is useful when the current question is referencing the chat history\n",
    "\n",
    "contextualize_q_system_prompt = (\n",
    "    \"Given a chat history and the latest user question \"\n",
    "    \"which might reference context in the chat history, \"\n",
    "    \"formulate a standalone question which can be understood \"\n",
    "    \"without the chat history. Do NOT answer the question, \"\n",
    "    \"just reformulate it if needed and otherwise return it as is.\"\n",
    ")\n",
    "\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}\n",
    "\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "conversational_rag_chain = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"answer\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The best practices for Python code style include:\\n\\n1. **Linting:** Use pylint to check your code for errors and enforce coding standards.\\n2. **Comments and Docstrings:** Use proper docstring format as per PEP 257, starting with a summary line and following with more details if necessary, all within triple double quotes.\\n3. **Consistency:** Maintain consistency with the existing code style in the project, ensuring that your additions blend seamlessly with the surrounding code.\\n\\nFor more detailed guidelines, refer to the Google Python Style Guide.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_rag_chain.invoke(\n",
    "    {\"input\": \"What are the best practices for Python code style?\"},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": \"testing\"}\n",
    "    },  # constructs a key \"testing\" in `store` to store the chat history of the session\n",
    ")[\"answer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent with custom tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenericInputSchema(BaseModel):\n",
    "    \"\"\"Inputs for url navigation tool.\"\"\"\n",
    "    domain: str = Field(\n",
    "        description=\"The domain of the website you want to navigate to.\")\n",
    "\n",
    "class ParamInputSchema(BaseModel):\n",
    "    \"\"\"Inputs API payload.\"\"\"\n",
    "    params: str = Field(\n",
    "        description=\"The input string with the format 'dsid, lot, type', which can be used to create a dictionary with the keys 'name:p.dsid', 'name:p.lot', and 'name:p.type'.\")\n",
    "    \n",
    "class payload_formatter(BaseTool):\n",
    "    name: str = \"payload_formatter\"\n",
    "    args_schema: Optional[Type[BaseModel]] = ParamInputSchema\n",
    "    description: str = \"\"\"\n",
    "    \n",
    "    payload formatter is a tool that takes an input string with the format 'dsid, lot, type' and returns a dictionary with the keys 'name:p.dsid', 'name:p.lot', and 'name:p.type'.\n",
    "    \"\"\"\n",
    "    def format_input(self,input_string):\n",
    "        parts = input_string.replace('.', '').split(',')\n",
    "        parts = [part.strip() for part in parts if part.strip() != '']\n",
    "        if len(parts) != 3:\n",
    "            raise ValueError(\"Please check that the input contains exactly three parts: dsid, lot, and pid.\")\n",
    "        for part in parts:\n",
    "            if part[0].isalpha() and part[-1].isalpha() and part[1:-1].isdigit():\n",
    "                dsid = part\n",
    "            elif part.isdigit():\n",
    "                lot = part\n",
    "            else:\n",
    "                type_ = part\n",
    "        output = {\n",
    "            \"name:p.dsid\": dsid,\n",
    "            \"name:p.lot\": lot,\n",
    "            \"name:p.type\": type_\n",
    "        }\n",
    "        return output\n",
    "\n",
    "    def _run(self, params: str):\n",
    "        return self.format_input(params)\n",
    "    \n",
    "class url_navigator(BaseTool):\n",
    "    name: str = \"map_viewer_url\"\n",
    "    args_schema: Optional[Type[BaseModel]] = GenericInputSchema\n",
    "    description: str = \"\"\"\n",
    "    \n",
    "    url navigator is a tool that takes a domain as input and returns the url of the website you want to navigate to.\n",
    "    \"\"\"\n",
    "\n",
    "    def _run(self, domain: str):\n",
    "        return f\"www.{domain}.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [url_navigator(), payload_formatter()] # create a list of tools which will be the input of create_react_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful assistant\"\n",
    "# not compulsory but I want to remind it the tools that it has access to\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = create_react_agent(\n",
    "    llm, tools, messages_modifier=system_message, checkpointer=memory\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the formatted payload:\n",
      "\n",
      "- **name:p.dsid**: B47R\n",
      "- **name:p.lot**: 1952591\n",
      "- **name:p.type**: FPC\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"testing123\"}}\n",
    "\n",
    "print(\n",
    "    app.invoke(\n",
    "        {\n",
    "            \"messages\": [\n",
    "                (\"user\", \"1952591,,,,,B47R,FPC\")\n",
    "            ]\n",
    "        },\n",
    "        config,\n",
    "    )[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can navigate to [LangChain](http://www.langchain.com) by clicking on the link.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    app.invoke(\n",
    "        {\n",
    "            \"messages\": [\n",
    "                (\"Navigate to langchain\")\n",
    "            ]\n",
    "        },\n",
    "        config,\n",
    "    )[\"messages\"][-1].content\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding in other built-in tools (e.g., search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = TavilySearchResults(max_results=2)\n",
    "\n",
    "tools = [url_navigator(), payload_formatter(), search]\n",
    "\n",
    "system_message = \"You are a helpful assistant and you know how to use url navigator tool, payload formatter tool and tavily search.\"\n",
    "# not compulsory but I want to remind it the tools that it has access to\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = create_react_agent(\n",
    "    llm, tools, messages_modifier=system_message, checkpointer=memory\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"test-thread\"}}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some of the latest news articles about Conor McGregor:\n",
      "\n",
      "1. **Conor McGregor's Silence: A Sign of Renewed Focus?**\n",
      "   - Chael Sonnen and Daniel Cormier discuss McGregor's silence and its implications for his upcoming return.\n",
      "   - [Read more](https://www.mmafighting.com/2024/6/4/24171284/chael-sonnen-wonders-conor-mcgregor-silence-sign-of-renewed-focus-daniel-cormier-finds-it-worrisome)\n",
      "\n",
      "2. **Conor McGregor's Return Teased in Promo for UFC 303**\n",
      "   - Conor McGregor is set to return to the octagon on June 29 to fight Michael Chandler at UFC 303.\n",
      "   - [Read more](https://www.mmafighting.com/2024/5/5/24149315/watch-conor-mcgregor-return-teased-in-spine-tingling-promo-ahead-of-ufc-303)\n",
      "\n",
      "Feel free to check out the articles for more details!\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    app.invoke(\n",
    "        {\n",
    "            \"messages\": [\n",
    "                (\"Search for the latest Conor McGregor news\")\n",
    "            ]\n",
    "        },\n",
    "        config,\n",
    "    )[\"messages\"][-1].content\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "knowledge_retriever = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"style_guide_retriever\",\n",
    "    \"Searches and returns key pointers for programming languages from google style guide\",\n",
    ")\n",
    "tools = [url_navigator(), payload_formatter(), search, knowledge_retriever]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful assistant and you know how to use url navigator tool, payload formatter tool, tavily search and google style guide retriever.\"\n",
    "\n",
    "\n",
    "app = create_react_agent(\n",
    "    llm, tools, messages_modifier=system_message, checkpointer=memory\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"chat-thread\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Key Differences Between Python and R Style Guides\n",
      "\n",
      "1. **Naming Conventions**:\n",
      "   - **Python**: Typically uses `snake_case` for variables and functions.\n",
      "   - **R**: Uses `BigCamelCase` for functions and prefixes private functions with a dot (`.`).\n",
      "\n",
      "2. **Assignment Operators**:\n",
      "   - **Python**: Uses the standard `=` for assignment.\n",
      "   - **R**: Uses `<-` for assignment. The right-hand assignment (`->`) is discouraged.\n",
      "\n",
      "3. **Docstrings and Comments**:\n",
      "   - **Python**: Emphasizes the use of docstrings (`\"\"\"`) for documenting modules, classes, and functions. Inline comments should be used sparingly and should be clear.\n",
      "   - **R**: Focuses more on comments and ensuring they are clear, well-written, and use proper punctuation and grammar.\n",
      "\n",
      "4. **Power Features and Advanced Techniques**:\n",
      "   - **Python**: Advises against using advanced features like custom metaclasses, access to bytecode, reflection, and dynamic inheritance as they can make code harder to read and maintain.\n",
      "   - **R**: Does not have a specific section on avoiding advanced features but emphasizes clarity and simplicity in code.\n",
      "\n",
      "5. **Use of Attach**:\n",
      "   - **Python**: Does not have an equivalent function like `attach()` in R.\n",
      "   - **R**: Strongly advises against using `attach()` due to the potential for creating errors.\n",
      "\n",
      "6. **Linting**:\n",
      "   - **Python**: Recommends using `pylint` to catch errors and enforce style guidelines.\n",
      "   - **R**: Does not mention a specific linting tool in the style guide.\n",
      "\n",
      "7. **Explicit Returns**:\n",
      "   - **Python**: Functions should use `return` to explicitly return a value.\n",
      "   - **R**: Strongly recommends using `return()` instead of relying on implicit returns.\n",
      "\n",
      "8. **Shebang Line**:\n",
      "   - **Python**: Main script files should start with `#!/usr/bin/env python3` or `#!/usr/bin/python3`.\n",
      "   - **R**: Does not mention the use of a shebang line.\n",
      "\n",
      "### Examples\n",
      "\n",
      "**Python Function Example**:\n",
      "```python\n",
      "def add_values(x, y):\n",
      "    \"\"\"Add two values and return the result.\"\"\"\n",
      "    return x + y\n",
      "```\n",
      "\n",
      "**R Function Example**:\n",
      "```r\n",
      "AddValues <- function(x, y) {\n",
      "  return(x + y)\n",
      "}\n",
      "```\n",
      "\n",
      "**Python Comment Example**:\n",
      "```python\n",
      "# This is a comment in Python\n",
      "foo = 1000  # Inline comment\n",
      "```\n",
      "\n",
      "**R Comment Example**:\n",
      "```r\n",
      "# This is a comment in R\n",
      "foo <- 1000  # Inline comment\n",
      "```\n",
      "\n",
      "### Summary\n",
      "While both languages emphasize readability and clarity, Python's style guide is more focused on avoiding complex language features and using linting tools to enforce style, whereas R's style guide emphasizes clear naming conventions, avoiding certain functions like `attach()`, and ensuring comments are well-written and grammatically correct.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    app.invoke(\n",
    "        {\n",
    "            \"messages\": [\n",
    "                (\"What are some differences between Python and R's style guide?\")\n",
    "            ]\n",
    "        },\n",
    "        config,\n",
    "    )[\"messages\"][-1].content\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-agent-with-gemini-6S2l9oJE-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
