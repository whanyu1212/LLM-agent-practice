{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace the standard sqlite3 module with pysqlite3\n",
    "# for compatibility with Chroma\n",
    "__import__('pysqlite3')\n",
    "import sys\n",
    "sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')\n",
    "\n",
    "\n",
    "import langchain\n",
    "import os\n",
    "import bs4\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "from langgraph.prebuilt import chat_agent_executor\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "# load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "# credential json not required if you are working within vertex AI\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/workspaces/LLM-agent-with-Gemini/fleet-anagram-244304-7dafcc771b2f.json\"\n",
    "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\") # only if you are using text embedding model from google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. URL: https://www.datacamp.com/blog/what-is-julia-used-for\n",
      "Content: The Julia website lists many of the language's applications, and we've highlighted some of the key ones below: 6. Pharmaceutical Modelling and Development. Julia is widely used in the medical field. Researchers use Julia to identify and test new drugs, optimize treatments, and for diagnosis and treatments.\n",
      "\n",
      "2. URL: https://en.wikipedia.org/wiki/Julia_(programming_language)\n",
      "Content: Julia is a high-level, general-purpose dynamic programming language, most commonly used for numerical analysis and computational science. Distinctive aspects of Julia's design include a type system with parametric polymorphism and the use of multiple dispatch as a core programming paradigm, efficient garbage collection, and a just-in-time (JIT) compiler (with support for ahead-of-time ...\n",
      "\n",
      "3. URL: https://julialang.org/\n",
      "Content: Julia has been downloaded over 45 million times and the Julia community has registered over 10,000 Julia packages for community use. These include various mathematical libraries, data manipulation tools, and packages for general purpose computing. In addition to these, you can easily use libraries from Python, R, C/Fortran, C++, and Java .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search = TavilySearchResults(max_results=3)\n",
    "result = search.invoke(\"What is Julia language known for?\")\n",
    "\n",
    "# Formatting\n",
    "for i, item in enumerate(result, start=1):\n",
    "    print(f\"{i}. URL: {item['url']}\\nContent: {item['content']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_paths = [\n",
    "    \"https://google.github.io/styleguide/pyguide.html\",\n",
    "    \"https://google.github.io/styleguide/Rguide.html\",\n",
    "    # \"https://google.github.io/styleguide/cppguide.html\",\n",
    "    # \"https://google.github.io/styleguide/go/\",\n",
    "    # \"https://google.github.io/styleguide/javaguide.html\",\n",
    "    # \"https://google.github.io/styleguide/jsguide.html\",\n",
    "    # \"https://google.github.io/styleguide/tsguide.html\"\n",
    "]\n",
    "\n",
    "# Only keep post title, headers, and content from the full HTML.\n",
    "# bs4_strainer = bs4.SoupStrainer(class_=(\"post-title\", \"post-header\", \"post-content\"))\n",
    "\n",
    "docs = []\n",
    "for path in web_paths:\n",
    "    loader = WebBaseLoader(web_paths=(path,),\n",
    "                        #    bs_kwargs={\"parse_only\": bs4_strainer}\n",
    "    )\n",
    "    docs += loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88189"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "len(all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_splits[-1].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.cache/pypoetry/virtualenvs/llm-agent-with-gemini-6S2l9oJE-py3.10/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/home/codespace/.cache/pypoetry/virtualenvs/llm-agent-with-gemini-6S2l9oJE-py3.10/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "vectorstore = FAISS.from_documents(documents=all_splits, embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\"))\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"programming_style_guide_search\",\n",
    "    \"Reference for information about styling rules for programming languages\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [search, retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatVertexAI(model=\"gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = chat_agent_executor.create_tool_calling_executor(llm, tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def print_formatted_response(response):\n",
    "    for i in range(4):\n",
    "        if i == 0:\n",
    "            print(f\"Question: {response['messages'][0].content}\")\n",
    "        elif i == 1:\n",
    "            function_call = response['messages'][i].additional_kwargs.get('function_call', {})\n",
    "            name = function_call.get('name', '')\n",
    "            print(f\"Tool: {name}\")\n",
    "        elif i == 2:\n",
    "            data = json.loads(response['messages'][2].content)\n",
    "            print(\"Citation:\")\n",
    "            for item in data:\n",
    "                print(item['url'])\n",
    "        else:\n",
    "            print(f\"Answer: {response['messages'][3].content}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content=\"What are the differences between langchain and llamaindex, search if it's not in retriever\", id='8dc0fb80-6e77-43b4-af88-1874425df09c'),\n",
       " AIMessage(content='', additional_kwargs={'function_call': {'name': 'programming_style_guide_search', 'arguments': '{\"query\": \"differences between langchain and llamaindex\"}'}}, response_metadata={'is_blocked': False, 'safety_ratings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability_label': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability_label': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability_label': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability_label': 'NEGLIGIBLE', 'blocked': False}], 'usage_metadata': {'prompt_token_count': 103, 'candidates_token_count': 16, 'total_token_count': 119}}, id='run-e1977607-44d7-406a-b345-fa420a9f1847-0', tool_calls=[{'name': 'programming_style_guide_search', 'args': {'query': 'differences between langchain and llamaindex'}, 'id': '115eaf6c-e5b0-4f7e-a5b2-b5ff80671d24'}]),\n",
       " ToolMessage(content='2.19.4 Decision\\nAvoid these features in your code.\\nStandard library modules and classes that internally use these features are okay\\nto use (for example, abc.ABCMeta, dataclasses, and enum).\\n\\n\\n\\n2.20 Modern Python: from __future__ imports\\nNew language version semantic changes may be gated behind a special future\\nimport to enable them on a per-file basis within earlier runtimes.\\n\\n\\n\\n2.20.1 Definition\\nBeing able to turn on some of the more modern features via from __future__\\nimport statements allows early use of features from expected future Python\\nversions.\\n\\n\\n\\n2.20.2 Pros\\nThis has proven to make runtime version upgrades smoother as changes can be made\\non a per-file basis while declaring compatibility and preventing regressions\\nwithin those files. Modern code is more maintainable as it is less likely to\\naccumulate technical debt that will be problematic during future runtime\\nupgrades.\\n\\n2.17.2 Pros\\nElegantly specifies some transformation on a method; the transformation might\\neliminate some repetitive code, enforce invariants, etc.\\n\\n\\n\\n2.17.3 Cons\\nDecorators can perform arbitrary operations on a function’s arguments or return\\nvalues, resulting in surprising implicit behavior. Additionally, decorators\\nexecute at object definition time. For module-level objects (classes, module\\nfunctions, …) this happens at import time. Failures in decorator code are\\npretty much impossible to recover from.\\n\\nchoices unspecified by the global style. Consistency should not generally be\\nused as a justification to do things in an old style without considering the\\nbenefits of the new style, or the tendency of the codebase to converge on newer\\nstyles over time.\\n\\n2.2.3 Cons\\nModule names can still collide. Some module names are inconveniently long.\\n\\n\\n\\n2.2.4 Decision\\n\\nUse import x for importing packages and modules.\\nUse from x import y where x is the package prefix and y is the module\\nname with no prefix.\\nUse from x import y as z in any of the following circumstances:\\n    \\nTwo modules named y are to be imported.\\ny conflicts with a top-level name defined in the current module.\\ny conflicts with a common parameter name that is part of the public\\nAPI (e.g., features).\\ny is an inconveniently long name.\\ny is too generic in the context of your code (e.g., from\\nstorage.file_system import options as fs_options).\\n\\n\\nUse import y as z only when z is a standard abbreviation (e.g., import\\nnumpy as np).\\n\\nFor example the module sound.effects.echo may be imported as follows:\\nfrom sound.effects import echo\\n...\\necho.EchoFilter(input, output, delay=0.7, atten=4)\\n\\n2.5.1 Definition\\nModule-level values or class attributes that can get mutated during program\\nexecution.\\n\\n\\n\\n2.5.2 Pros\\nOccasionally useful.\\n\\n\\n\\n2.5.3 Cons\\n\\n\\nBreaks encapsulation: Such design can make it hard to achieve valid\\nobjectives. For example, if global state is used to manage a database\\nconnection, then connecting to two different databases at the same time\\n(such as for computing differences during a migration) becomes difficult.\\nSimilar problems easily arise with global registries.\\n\\n\\nHas the potential to change module behavior during the import, because\\nassignments to global variables are done when the module is first imported.', name='programming_style_guide_search', id='64f16705-fe9f-42bd-9f53-5d012838588a', tool_call_id='115eaf6c-e5b0-4f7e-a5b2-b5ff80671d24'),\n",
       " AIMessage(content='I am sorry, I cannot answer your question. The available tools are not sufficient to answer your question.  The `programming_style_guide_search` tool is not relevant to the topic. \\n', response_metadata={'is_blocked': False, 'safety_ratings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability_label': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability_label': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability_label': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability_label': 'NEGLIGIBLE', 'blocked': False}], 'usage_metadata': {'prompt_token_count': 851, 'candidates_token_count': 42, 'total_token_count': 893}}, id='run-16c69b0c-ceab-4fc0-a281-fd576f45454e-0')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = agent_executor.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"What are the differences between langchain and llamaindex, search if it's not in retriever\")]}\n",
    ")\n",
    "response[\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaIndex and LangChain are both frameworks designed to simplify the development of applications using large language models (LLMs). Here are some key differences:\n",
      "\n",
      "* **Purpose and Scope:**\n",
      "    * **LangChain** is a more multipurpose framework, suitable for building a wider range of applications, including chatbots, data analysis tools, and more. It focuses on providing flexibility and extensive customization options.\n",
      "    * **LlamaIndex** is more specialized and focuses on facilitating interactions between LLMs and external data. It excels in applications that require querying, summarizing, or extracting information from various data sources.\n",
      "\n",
      "* **Features:**\n",
      "    * **LangChain** offers a broader selection of integrations with external tools and APIs, making it more versatile. It provides features for prompt management, chain building (combining multiple LLM calls), and agent systems. \n",
      "    * **LlamaIndex** shines in its data indexing and querying capabilities. It offers various data connectors and provides a structured way to store and access data within an LLM application.\n",
      "\n",
      "* **Ease of Use:** \n",
      "    * **LlamaIndex** is generally considered easier to get started with, especially for tasks related to data integration and querying. Its simpler API and pre-built data structures can lead to faster development times.\n",
      "    * **LangChain**, while more powerful, might have a steeper learning curve due to its wider range of features and customization options. \n",
      "\n",
      "**Choosing the right framework depends on your specific needs.** If you're building an application centered around data interactions and require strong indexing and querying capabilities, LlamaIndex could be a good choice. If you need a more versatile framework for building complex LLM applications with custom integrations, LangChain might be a better fit.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'function_call': {'name': 'tavily_search_results_json', 'arguments': '{\"query\": \"What is Vajra\"}'}}, response_metadata={'is_blocked': False, 'safety_ratings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability_label': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability_label': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability_label': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability_label': 'NEGLIGIBLE', 'blocked': False}], 'usage_metadata': {'prompt_token_count': 87, 'candidates_token_count': 13, 'total_token_count': 100}}, id='run-3c2e77a0-259e-4ec0-a7ab-ebeaad9402ac-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'What is Vajra'}, 'id': '1f586c99-46f4-4a3b-b1a1-5cc247a80633'}])]}}\n",
      "----\n",
      "{'tools': {'messages': [ToolMessage(content='[{\"url\": \"https://www.britannica.com/topic/vajra\", \"content\": \"vajra, five-pronged ritual object extensively employed in Tibetan Buddhist ceremonies.It is the symbol of the Vajray\\\\u0101na school of Buddhism.. Vajra, in Sanskrit, has both the meanings of \\\\\"thunderbolt\\\\\" and \\\\\"diamond.\\\\\"Like the thunderbolt, the vajra cleaves through ignorance. The thunderbolt was originally the symbol of the Hindu rain god Indra (who became the Buddhist \\\\u015aakra) and was ...\"}, {\"url\": \"https://www.learnreligions.com/vajra-or-dorje-449881\", \"content\": \"The vajra also is a literal ritual object associated with Tibetan Buddhism, also called by its Tibetan name, Dorje. It is the symbol of the Vajrayana school of Buddhism, which is the tantric branch that contains rituals said to allow a follower to achieve enlightenment in a single lifetime, in a thunderbolt flash of indestructible clarity.\"}, {\"url\": \"https://en.wikipedia.org/wiki/Vajra\", \"content\": \"The Vajra (Sanskrit: \\\\u0935\\\\u091c\\\\u094d\\\\u0930, lit. \\'Thunderbolt\\', IAST: Vajra) is a legendary and ritualistic tool, symbolizing the properties of a diamond (indestructibility) and a thunderbolt (irresistible force). In Hinduism, it has also been associated with weapons. The use of the bell and vajra as symbolic and ritual tools is found in all schools of Tibetan Buddhism.\"}]', name='tavily_search_results_json', id='aa6999b7-e087-4412-b3a1-104d5cd062ff', tool_call_id='1f586c99-46f4-4a3b-b1a1-5cc247a80633')]}}\n",
      "----\n",
      "{'agent': {'messages': [AIMessage(content='The Vajra is a five-pronged ritual object extensively employed in Tibetan Buddhist ceremonies. It is the symbol of the Vajrayana school of Buddhism, which is the tantric branch that contains rituals said to allow a follower to achieve enlightenment in a single lifetime. The word Vajra comes from Sanskrit and has both the meanings of \"thunderbolt\" and \"diamond.\"  It symbolizes the properties of a diamond (indestructibility) and a thunderbolt (irresistible force). It is said to cleave through ignorance.  The vajra was originally the symbol of the Hindu rain god Indra (who became the Buddhist Shakra). \\n', response_metadata={'is_blocked': False, 'safety_ratings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability_label': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability_label': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability_label': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability_label': 'NEGLIGIBLE', 'blocked': False}], 'citation_metadata': {'citations': [{'start_index': 10, 'end_index': 141, 'uri': 'https://docslib.org/doc/7667613/exploring-tibet-information-and-guide-to-cultural-artifacts', 'title': '', 'license_': ''}, {'start_index': 95, 'end_index': 269, 'uri': 'https://www.learnreligions.com/vajra-or-dorje-449881', 'title': '', 'license_': ''}]}, 'usage_metadata': {'prompt_token_count': 459, 'candidates_token_count': 129, 'total_token_count': 588}}, id='run-288b2bad-b4f2-4259-89d9-f03a8f0a1fa2-0')]}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "# streamin\n",
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"What is Vajra\")]}\n",
    "):\n",
    "    print(chunk)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = chat_agent_executor.create_tool_calling_executor(\n",
    "    llm, tools, checkpointer=memory\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='Nice to meet you, Hanyu! 👋 What can I do for you today? 😊 \\n', response_metadata={'is_blocked': False, 'safety_ratings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability_label': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability_label': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability_label': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability_label': 'NEGLIGIBLE', 'blocked': False}], 'usage_metadata': {'prompt_token_count': 90, 'candidates_token_count': 20, 'total_token_count': 110}}, id='run-a64ff6c5-c971-4ddf-b0b5-34044e1523c2-0')]}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"Hi, I'm Hanyu\")]}, config\n",
    "):\n",
    "    print(chunk)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='Your name is Hanyu! 😊  I remember that from our first interaction.  Is there anything else I can help you with? \\n', response_metadata={'is_blocked': False, 'safety_ratings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability_label': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability_label': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability_label': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability_label': 'NEGLIGIBLE', 'blocked': False}], 'usage_metadata': {'prompt_token_count': 116, 'candidates_token_count': 29, 'total_token_count': 145}}, id='run-406fb25b-6f74-4e7d-8676-f8376bb26c1b-0')]}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"What's my name?\")]}, config\n",
    "):\n",
    "    print(chunk)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're getting into the exciting world of LLM agents! Here are some use cases for them, ranging from practical to innovative:\n",
      "\n",
      "**Practical Use Cases:**\n",
      "\n",
      "* **Customer Service Chatbots:** LLMs can handle initial customer inquiries, provide product information, and even resolve simple issues. This frees up human agents for more complex tasks.\n",
      "* **Personal Assistants:** An LLM agent could manage your calendar, send reminders, book appointments, and even make recommendations based on your preferences.\n",
      "* **Content Creation:**  LLM agents can assist with writing articles, blog posts, social media content, and even code, significantly speeding up the process and potentially improving quality.\n",
      "* **Research Assistants:** These agents could analyze research papers, identify relevant sources, and summarize findings, making research more efficient.\n",
      "* **Data Analysis:** LLMs can analyze large datasets, identify patterns, and generate reports, empowering data-driven decision-making.\n",
      "\n",
      "**Innovative Use Cases:**\n",
      "\n",
      "* **Personalized Learning:**  LLMs can adapt to individual learning styles, create customized learning plans, and provide personalized feedback, making education more effective.\n",
      "* **Creative Storytelling:** LLM agents could co-write stories, poems, or scripts with humans, leveraging their language skills and creative potential.\n",
      "* **Virtual Companionship:** These agents could provide companionship, engage in conversations, and even play games, offering a sense of connection for people who are isolated.\n",
      "* **Automated Marketing:** LLM agents could analyze customer data, personalize marketing messages, and even create targeted advertisements.\n",
      "* **Healthcare Assistance:**  LLMs could analyze medical data, assist with diagnosis, provide patient education, and even remind patients to take their medications.\n",
      "\n",
      "**Important Considerations:**\n",
      "\n",
      "* **Safety and Ethics:** It's crucial to develop LLM agents responsibly, ensuring they are not used to spread misinformation, perpetuate biases, or harm individuals.\n",
      "* **Transparency and Explainability:** Users should understand how LLM agents work and be able to trust their decisions.\n",
      "* **Data Privacy:**  LLM agents may access sensitive information, so it's crucial to ensure data privacy and security.\n",
      "\n",
      "**The Future is Bright:**\n",
      "\n",
      "LLM agents have the potential to revolutionize many industries and aspects of our lives. It's an exciting time to be exploring their capabilities and potential applications. \n",
      "\n",
      "**What specific areas of LLM agents are you most interested in? I'd be happy to discuss them further!** \n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = agent_executor.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"Suggest some use cases for LLM Agent\")]}, config\n",
    ")\n",
    "\n",
    "print(response[\"messages\"][-1].content)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-agent-with-gemini-6S2l9oJE-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
